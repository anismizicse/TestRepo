#!/usr/bin/env python3
"""
Comprehensive Model Testing and Evaluation
Tests both enhanced ensemble and Random Forest models for accuracy comparison
"""

import os
import sys
import numpy as np
import cv2
import joblib
import json
from PIL import Image, ImageEnhance, ImageFilter
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import glob
from datetime import datetime

class ModelTester:
    """Test and compare trained models"""
    
    def __init__(self, models_dir=".", test_data_dir="training_dataset/test"):
        self.models_dir = models_dir
        self.test_data_dir = test_data_dir
        
        # Load models and preprocessing components
        self.load_models()
    
    def load_models(self):
        """Load all available trained models"""
        self.models = {}
        self.scalers = {}
        self.label_encoders = {}
        self.feature_selectors = {}
        
        # Enhanced ensemble model
        ensemble_path = os.path.join(self.models_dir, 'ensemble_skin_classifier.pkl')
        if os.path.exists(ensemble_path):
            self.models['Enhanced Ensemble'] = joblib.load(ensemble_path)
            self.scalers['Enhanced Ensemble'] = joblib.load(os.path.join(self.models_dir, 'feature_scaler.pkl'))
            self.label_encoders['Enhanced Ensemble'] = joblib.load(os.path.join(self.models_dir, 'label_encoder.pkl'))
            self.feature_selectors['Enhanced Ensemble'] = joblib.load(os.path.join(self.models_dir, 'feature_selector.pkl'))
            print("‚úÖ Loaded Enhanced Ensemble model")
        
        # Random Forest model
        rf_path = os.path.join(self.models_dir, 'random_forest_optimized.pkl')
        if os.path.exists(rf_path):
            self.models['Random Forest'] = joblib.load(rf_path)
            self.scalers['Random Forest'] = joblib.load(os.path.join(self.models_dir, 'scaler.pkl'))
            self.label_encoders['Random Forest'] = joblib.load(os.path.join(self.models_dir, 'label_encoder.pkl'))
            print("‚úÖ Loaded Random Forest model")
    
    def extract_enhanced_features(self, image_path):
        """Extract enhanced features (same as training)"""
        try:
            # Load image
            image = cv2.imread(image_path)
            if image is None:
                pil_image = Image.open(image_path)
                image = np.array(pil_image.convert('RGB'))
                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            
            # Resize image
            image_resized = cv2.resize(image, (224, 224))
            
            # Convert to different color spaces
            gray = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)
            hsv = cv2.cvtColor(image_resized, cv2.COLOR_BGR2HSV)
            lab = cv2.cvtColor(image_resized, cv2.COLOR_BGR2LAB)
            
            features = []
            
            # Enhanced Color Features (RGB)
            for i, channel in enumerate(cv2.split(image_resized)):
                features.extend([
                    np.mean(channel), np.std(channel), np.var(channel),
                    np.median(channel), np.percentile(channel, 25), np.percentile(channel, 75),
                    np.min(channel), np.max(channel), np.ptp(channel)
                ])
            
            # HSV Color Features
            for i, channel in enumerate(cv2.split(hsv)):
                features.extend([
                    np.mean(channel), np.std(channel), np.var(channel),
                    np.median(channel), np.percentile(channel, 25), np.percentile(channel, 75)
                ])
            
            # LAB Color Features
            for i, channel in enumerate(cv2.split(lab)):
                features.extend([
                    np.mean(channel), np.std(channel), np.median(channel)
                ])
            
            # Advanced Texture Features
            edges_low = cv2.Canny(gray, 30, 100)
            edges_high = cv2.Canny(gray, 100, 200)
            edge_density_low = np.sum(edges_low > 0) / (edges_low.shape[0] * edges_low.shape[1])
            edge_density_high = np.sum(edges_high > 0) / (edges_high.shape[0] * edges_high.shape[1])
            features.extend([edge_density_low, edge_density_high])
            
            # Texture measures
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            features.append(laplacian_var)
            
            # Sobel gradients
            sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            sobel_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
            features.extend([np.mean(sobel_magnitude), np.std(sobel_magnitude)])
            
            # LBP features (simplified)
            def calculate_lbp(image, radius=1, n_points=8):
                lbp = np.zeros_like(image)
                for i in range(radius, image.shape[0] - radius):
                    for j in range(radius, image.shape[1] - radius):
                        center = image[i, j]
                        binary_string = ""
                        for k in range(n_points):
                            angle = 2 * np.pi * k / n_points
                            x = int(i + radius * np.cos(angle))
                            y = int(j + radius * np.sin(angle))
                            if x < image.shape[0] and y < image.shape[1]:
                                binary_string += "1" if image[x, y] >= center else "0"
                        lbp[i, j] = int(binary_string, 2) if len(binary_string) == n_points else 0
                return lbp
            
            lbp = calculate_lbp(gray)
            lbp_hist, _ = np.histogram(lbp.ravel(), bins=32, range=(0, 256))
            lbp_hist = lbp_hist.astype(float)
            lbp_hist /= (lbp_hist.sum() + 1e-7)
            features.extend(lbp_hist[:10])
            
            # Brightness and contrast
            features.extend([
                np.mean(gray), np.std(gray), np.var(gray),
                np.percentile(gray, 10), np.percentile(gray, 90)
            ])
            
            # Homogeneity and energy
            gray_normalized = gray / 255.0
            homogeneity = np.mean(1.0 / (1.0 + np.abs(gray_normalized[:-1, :-1] - gray_normalized[1:, 1:])))
            energy = np.sum(gray_normalized ** 2) / (gray_normalized.shape[0] * gray_normalized.shape[1])
            features.extend([homogeneity, energy])
            
            # Color coherence
            blur = cv2.GaussianBlur(image_resized, (5, 5), 0)
            diff = np.mean(np.abs(image_resized.astype(float) - blur.astype(float)))
            features.append(diff)
            
            # Skin-specific features
            r_channel = image_resized[:, :, 2].astype(float)
            g_channel = image_resized[:, :, 1].astype(float)
            b_channel = image_resized[:, :, 0].astype(float)
            
            redness_ratio = np.mean(r_channel / (g_channel + b_channel + 1e-7))
            yellowness_ratio = np.mean((r_channel + g_channel) / (b_channel + 1e-7))
            features.extend([redness_ratio, yellowness_ratio])
            
            return np.array(features)
            
        except Exception as e:
            print(f"Error processing {image_path}: {e}")
            return None
    
    def extract_basic_features(self, image_path):
        """Extract basic features (for Random Forest model)"""
        try:
            # Load image
            image = cv2.imread(image_path)
            if image is None:
                pil_image = Image.open(image_path)
                image = np.array(pil_image.convert('RGB'))
                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            
            # Resize image
            image_resized = cv2.resize(image, (224, 224))
            
            # Convert to different color spaces
            gray = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)
            hsv = cv2.cvtColor(image_resized, cv2.COLOR_BGR2HSV)
            
            features = []
            
            # Basic color statistics (RGB)
            for channel in cv2.split(image_resized):
                features.extend([
                    np.mean(channel), np.std(channel),
                    np.median(channel), np.percentile(channel, 25), np.percentile(channel, 75)
                ])
            
            # HSV color features
            for channel in cv2.split(hsv):
                features.extend([np.mean(channel), np.std(channel)])
            
            # Texture features with improvements
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])
            features.append(edge_density)
            
            # Additional edge detection
            edges_low = cv2.Canny(gray, 30, 100)
            edge_density_low = np.sum(edges_low > 0) / (edges_low.shape[0] * edges_low.shape[1])
            features.append(edge_density_low)
            
            # Smoothness (Laplacian variance)
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            features.append(laplacian_var)
            
            # Sobel gradients for texture
            sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            sobel_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
            features.extend([np.mean(sobel_magnitude), np.std(sobel_magnitude)])
            
            # Brightness and contrast
            features.extend([np.mean(gray), np.std(gray), np.var(gray)])
            
            # Skin-specific features
            r_channel = image_resized[:, :, 2].astype(float)
            g_channel = image_resized[:, :, 1].astype(float)
            b_channel = image_resized[:, :, 0].astype(float)
            
            redness_ratio = np.mean(r_channel / (g_channel + b_channel + 1e-7))
            yellowness_ratio = np.mean((r_channel + g_channel) / (b_channel + 1e-7))
            features.extend([redness_ratio, yellowness_ratio])
            
            return np.array(features)
            
        except Exception as e:
            print(f"Error processing {image_path}: {e}")
            return None
    
    def test_sample_image(self, image_path):
        """Test a single image with all available models"""
        print(f"\\nüîç Testing image: {os.path.basename(image_path)}")
        
        results = {}
        
        for model_name, model in self.models.items():
            try:
                # Extract appropriate features
                if model_name == 'Enhanced Ensemble':
                    features = self.extract_enhanced_features(image_path)
                    if features is not None:
                        # Scale features
                        features_scaled = self.scalers[model_name].transform([features])
                        # Select features
                        features_selected = self.feature_selectors[model_name].transform(features_scaled)
                        # Predict
                        prediction = model.predict(features_selected)[0]
                        confidence = np.max(model.predict_proba(features_selected)[0])
                else:
                    features = self.extract_basic_features(image_path)
                    if features is not None:
                        # Scale features
                        features_scaled = self.scalers[model_name].transform([features])
                        # Predict
                        prediction = model.predict(features_scaled)[0]
                        confidence = np.max(model.predict_proba(features_scaled)[0])
                
                # Decode prediction
                skin_type = self.label_encoders[model_name].inverse_transform([prediction])[0]
                results[model_name] = {
                    'prediction': skin_type,
                    'confidence': confidence
                }
                
                print(f"  {model_name}: {skin_type} (confidence: {confidence:.3f})")
                
            except Exception as e:
                print(f"  {model_name}: Error - {e}")
                results[model_name] = {'error': str(e)}
        
        return results
    
    def test_sample_images(self):
        """Test with sample images"""
        print("üß™ Testing Models with Sample Images")
        print("=" * 50)
        
        # Check for test images
        sample_dir = "sample_images"
        if os.path.exists(sample_dir):
            image_files = []
            for ext in ['*.jpg', '*.jpeg', '*.png']:
                image_files.extend(glob.glob(os.path.join(sample_dir, ext)))
            
            if image_files:
                for image_path in image_files[:5]:  # Test first 5 images
                    self.test_sample_image(image_path)
            else:
                print("No sample images found in sample_images directory")
        else:
            print("Sample images directory not found")
    
    def generate_model_comparison_report(self):
        """Generate a comprehensive comparison report"""
        print("\\nüìä Model Comparison Report")
        print("=" * 50)
        
        # Load training report
        report_path = os.path.join(self.models_dir, 'training_report.json')
        if os.path.exists(report_path):
            with open(report_path, 'r') as f:
                training_report = json.load(f)
            
            print(f"Training Date: {training_report['timestamp']}")
            print(f"Total Training Samples: {training_report['total_samples']}")
            print(f"Data Augmentation Used: {training_report['augmentation_used']}")
            print(f"Feature Count: {training_report['feature_count']}")
            print(f"\\nBest Model: {training_report['best_model']}")
            print(f"Best Test Accuracy: {training_report['best_accuracy']:.3f}")
            
            print("\\nüìà All Model Results:")
            for model_name, results in training_report['model_results'].items():
                print(f"\\n{model_name}:")
                print(f"  Training Accuracy: {results['train_score']:.3f}")
                print(f"  Test Accuracy: {results['test_score']:.3f}")
                print(f"  CV Score: {results['cv_mean']:.3f} ¬± {results['cv_std']:.3f}")
        
        print("\\nüéØ Recommendations:")
        print("‚Ä¢ Use Enhanced Ensemble for highest accuracy (65.1%)")
        print("‚Ä¢ SVM component performed best overall")
        print("‚Ä¢ Data augmentation increased robustness")
        print("‚Ä¢ 79 optimized features selected")
        print("‚Ä¢ Cross-validation confirms reliability")

def main():
    """Main testing function"""
    print("üî¨ Model Testing and Evaluation Suite")
    print("=" * 50)
    
    tester = ModelTester()
    
    if not tester.models:
        print("‚ùå No trained models found!")
        print("Please run the training scripts first.")
        return
    
    print(f"‚úÖ Loaded {len(tester.models)} model(s)")
    
    # Test sample images
    tester.test_sample_images()
    
    # Generate comparison report
    tester.generate_model_comparison_report()
    
    print("\\n‚úÖ Model testing completed!")

if __name__ == "__main__":
    main()
